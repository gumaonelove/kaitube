{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14dc001",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c902884",
   "metadata": {},
   "source": [
    "## Зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f426ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda update -n base -c conda-forge conda -y\n",
    "# !conda install -c conda-forge ipywidgets -y\n",
    "# !conda install -c conda-forge datasets -y\n",
    "# !conda install -c conda-forge transformers -y\n",
    "# !conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y\n",
    "# %pip install evaluate -qq\n",
    "# %pip install rouge-score -qq\n",
    "# %pip install nltk -qq\n",
    "# %pip install absl-py -qq\n",
    "# %pip install transformers[sentencepiece] -qq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b31f4b8",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "100cedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import load_dataset, ClassLabel, Dataset\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02b3114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cbd94714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 2801.42it/s]\n"
     ]
    }
   ],
   "source": [
    "def del_timestamps(text):\n",
    "    text = text.split(\"]  \")[1:]\n",
    "    return \" \".join(text)\n",
    "\n",
    "list_texts = []\n",
    "for i in tqdm(range(500)):\n",
    "    with open(f'./dataset/{i}.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [del_timestamps(line.strip()) for line in lines]\n",
    "        lines = \" \".join(lines)\n",
    "        list_texts.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "caec04fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Давай поспорим на выпуск, вот типа, что я точно угадаю цену одного из предметов. Ох, зима. Доктор Кл'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_texts[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10eef9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = pd.Series(list_texts)\n",
    "train = train.rename(columns={'description': 'summary'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4765493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>stt_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.mp4</td>\n",
       "      <td>0.txt</td>\n",
       "      <td>Развлечения</td>\n",
       "      <td>Правильная цена I #3</td>\n",
       "      <td>С вами Макс Климток и это шоу Правильная цена!...</td>\n",
       "      <td>Давай поспорим на выпуск, вот типа, что я точн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.mp4</td>\n",
       "      <td>1.txt</td>\n",
       "      <td>Спорт/Игры</td>\n",
       "      <td>Три лошадиные силы | Выпуск №2</td>\n",
       "      <td>В этом новом выпуске нас ждут не менее новые и...</td>\n",
       "      <td>ты поедешь со мной в тверь это 2 выпуск В этом...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.mp4</td>\n",
       "      <td>2.txt</td>\n",
       "      <td>Блоги</td>\n",
       "      <td>Хашлама | Выпуск 4 | Силиконовый ПРЕСС Давы | ...</td>\n",
       "      <td>Привет, это Султан и Авет! Мы опять хаваем вку...</td>\n",
       "      <td>Добрый вечер, дорогие друзья, с вами шоу «Хошл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.mp4</td>\n",
       "      <td>3.txt</td>\n",
       "      <td>Путешествия</td>\n",
       "      <td>Прогулка по стране - Владивосток</td>\n",
       "      <td>Прогулка по Владивостоку. Самому большому горо...</td>\n",
       "      <td>СПОКОЙНАЯ МУЗЫКА Редактор субтитров Е.Воинова ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.mp4</td>\n",
       "      <td>4.txt</td>\n",
       "      <td>Искусство</td>\n",
       "      <td>Артмеханика. Выпуск 3. Татуировки + Mika Vino</td>\n",
       "      <td>Были ли татуировки на теле Николая II? Почему ...</td>\n",
       "      <td>ДИНАМИЧНАЯ МУЗЫКА ДИНАМИЧНАЯ МУЗЫКА АПЛОДИСМЕН...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_name stt_name category_name  \\\n",
       "0      0.mp4    0.txt   Развлечения   \n",
       "1      1.mp4    1.txt    Спорт/Игры   \n",
       "2      2.mp4    2.txt         Блоги   \n",
       "3      3.mp4    3.txt   Путешествия   \n",
       "4      4.mp4    4.txt     Искусство   \n",
       "\n",
       "                                               title  \\\n",
       "0                               Правильная цена I #3   \n",
       "1                     Три лошадиные силы | Выпуск №2   \n",
       "2  Хашлама | Выпуск 4 | Силиконовый ПРЕСС Давы | ...   \n",
       "3                   Прогулка по стране - Владивосток   \n",
       "4      Артмеханика. Выпуск 3. Татуировки + Mika Vino   \n",
       "\n",
       "                                             summary  \\\n",
       "0  С вами Макс Климток и это шоу Правильная цена!...   \n",
       "1  В этом новом выпуске нас ждут не менее новые и...   \n",
       "2  Привет, это Султан и Авет! Мы опять хаваем вку...   \n",
       "3  Прогулка по Владивостоку. Самому большому горо...   \n",
       "4  Были ли татуировки на теле Николая II? Почему ...   \n",
       "\n",
       "                                                text  \n",
       "0  Давай поспорим на выпуск, вот типа, что я точн...  \n",
       "1  ты поедешь со мной в тверь это 2 выпуск В этом...  \n",
       "2  Добрый вечер, дорогие друзья, с вами шоу «Хошл...  \n",
       "3  СПОКОЙНАЯ МУЗЫКА Редактор субтитров Е.Воинова ...  \n",
       "4  ДИНАМИЧНАЯ МУЗЫКА ДИНАМИЧНАЯ МУЗЫКА АПЛОДИСМЕН...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "741861d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = pd.read_csv('./dataset/video.csv')\n",
    "video = video.rename(columns={'description': 'summary', 'ru_videos': 'text'})\n",
    "video = video.dropna()\n",
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "629a25bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video_name</th>\n",
       "      <th>stt_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>eng_videos</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.mp4</td>\n",
       "      <td>0.txt</td>\n",
       "      <td>Развлечения</td>\n",
       "      <td>Правильная цена I #3</td>\n",
       "      <td>С вами Макс Климток и это шоу Правильная цена!...</td>\n",
       "      <td>A group of people are sitting at a table and o...</td>\n",
       "      <td>Группа людей сидит за столом, и один из них ес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.mp4</td>\n",
       "      <td>1.txt</td>\n",
       "      <td>Спорт/Игры</td>\n",
       "      <td>Три лошадиные силы | Выпуск №2</td>\n",
       "      <td>В этом новом выпуске нас ждут не менее новые и...</td>\n",
       "      <td>A man is standing in front of a bunch of cardb...</td>\n",
       "      <td>Мужчина стоит перед пучком картонных коробок, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.mp4</td>\n",
       "      <td>2.txt</td>\n",
       "      <td>Блоги</td>\n",
       "      <td>Хашлама | Выпуск 4 | Силиконовый ПРЕСС Давы | ...</td>\n",
       "      <td>Привет, это Султан и Авет! Мы опять хаваем вку...</td>\n",
       "      <td>A man and a woman are sitting at a table and t...</td>\n",
       "      <td>Мужчина и женщина сидят за столом и говорят о ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.mp4</td>\n",
       "      <td>3.txt</td>\n",
       "      <td>Путешествия</td>\n",
       "      <td>Прогулка по стране - Владивосток</td>\n",
       "      <td>Прогулка по Владивостоку. Самому большому горо...</td>\n",
       "      <td>A person is driving a vehicle down a busy stre...</td>\n",
       "      <td>Человек управляет транспортным средством по ож...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.mp4</td>\n",
       "      <td>4.txt</td>\n",
       "      <td>Искусство</td>\n",
       "      <td>Артмеханика. Выпуск 3. Татуировки + Mika Vino</td>\n",
       "      <td>Были ли татуировки на теле Николая II? Почему ...</td>\n",
       "      <td>A man and a woman are on a stage and a man is ...</td>\n",
       "      <td>Мужчина и женщина находятся на сцене, и мужчин...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 video_name stt_name category_name  \\\n",
       "0           0      0.mp4    0.txt   Развлечения   \n",
       "1           1      1.mp4    1.txt    Спорт/Игры   \n",
       "2           2      2.mp4    2.txt         Блоги   \n",
       "3           3      3.mp4    3.txt   Путешествия   \n",
       "4           4      4.mp4    4.txt     Искусство   \n",
       "\n",
       "                                               title  \\\n",
       "0                               Правильная цена I #3   \n",
       "1                     Три лошадиные силы | Выпуск №2   \n",
       "2  Хашлама | Выпуск 4 | Силиконовый ПРЕСС Давы | ...   \n",
       "3                   Прогулка по стране - Владивосток   \n",
       "4      Артмеханика. Выпуск 3. Татуировки + Mika Vino   \n",
       "\n",
       "                                             summary  \\\n",
       "0  С вами Макс Климток и это шоу Правильная цена!...   \n",
       "1  В этом новом выпуске нас ждут не менее новые и...   \n",
       "2  Привет, это Султан и Авет! Мы опять хаваем вку...   \n",
       "3  Прогулка по Владивостоку. Самому большому горо...   \n",
       "4  Были ли татуировки на теле Николая II? Почему ...   \n",
       "\n",
       "                                          eng_videos  \\\n",
       "0  A group of people are sitting at a table and o...   \n",
       "1  A man is standing in front of a bunch of cardb...   \n",
       "2  A man and a woman are sitting at a table and t...   \n",
       "3  A person is driving a vehicle down a busy stre...   \n",
       "4  A man and a woman are on a stage and a man is ...   \n",
       "\n",
       "                                                text  \n",
       "0  Группа людей сидит за столом, и один из них ес...  \n",
       "1  Мужчина стоит перед пучком картонных коробок, ...  \n",
       "2  Мужчина и женщина сидят за столом и говорят о ...  \n",
       "3  Человек управляет транспортным средством по ож...  \n",
       "4  Мужчина и женщина находятся на сцене, и мужчин...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c7e2a119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(video)\n",
    "dataset = dataset.train_test_split(test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "10c83f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'video_name', 'stt_name', 'category_name', 'title', 'summary', 'eng_videos', 'text', '__index_level_0__'],\n",
       "        num_rows: 95\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'video_name', 'stt_name', 'category_name', 'title', 'summary', 'eng_videos', 'text', '__index_level_0__'],\n",
       "        num_rows: 24\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1cdc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=2):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bd058fde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video_name</th>\n",
       "      <th>stt_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>eng_videos</th>\n",
       "      <th>text</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>61.mp4</td>\n",
       "      <td>61.txt</td>\n",
       "      <td>Искусство</td>\n",
       "      <td>Артмеханика. Выпуск 8. Кастомайзинг как искусство + концерт Parks, Squares and Alleys</td>\n",
       "      <td>Описание выпуска: Бренд и художник, как им найти друг друга?  Куда приведет тенденция к тотальной кастомизации? Скрытый фэшн от Жени Чеса и много еще чего в новом выпуске Артмеханики. Музыкальную часть программы украсили собой Parks, Squares and Alleys.</td>\n",
       "      <td>A man is giving a speech in front of a crowd and then a woman is standing next to him. A woman is talking to a group of people while a man is talking to a group of people. A group of people are sitting at a table and a woman is talking to them about something. A man and a woman are sitting at a table and a woman is talking to a man and a woman is talking to a man. A group of people are sitting at a table and playing a game of ping pong with each other. A man is standing in front of a camera and talking about a project he is working on. A man is sitting at a table and talking to a woman who is sitting next to him. A man is standing in front of a mirror and then a man is standing in front of a mirror and then a man is standing in front of a mirror A group of people are performing on stage while music is playing in the background and people are walking around. A man and a woman are playing rock, paper, scissors in front of a crowd of people. A man and a woman are playing a song on a stage in front of a crowd of people. A man is playing the drums on a stage in front of a crowd of people who are listening to him.</td>\n",
       "      <td>Мужчина выступает перед толпой, а затем женщина стоит рядом с ним. Женщина разговаривает с группой людей, в то время как мужчина разговаривает с группой людей. Группа людей сидит за столом, а женщина говорит с ними о чем-то. Мужчина и женщина сидят за столом, а женщина разговаривает с мужчиной, а женщина разговаривает с мужчиной. Группа людей сидит за столом и играет в пинг-понг друг с другом. Мужчина стоит перед камерой и говорит о проекте, над которым он работает. Мужчина сидит за столом и разговаривает с женщиной, которая сидит рядом с ним. Мужчина стоит перед зеркалом, а затем мужчина стоит перед зеркалом Группа людей выступает на сцене, в то время как музыка играет на заднем плане, и люди ходят вокруг. Мужчина и женщина играют рок, бумагу, ножницы перед толпой людей. Мужчина и женщина играют песню на сцене перед толпой людей. Мужчина и женщина играют на барабанах перед толпой людей.</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81</td>\n",
       "      <td>81.mp4</td>\n",
       "      <td>81.txt</td>\n",
       "      <td>Блоги</td>\n",
       "      <td>Под другим углом | Выпуск 4 | Что такое звук?</td>\n",
       "      <td>Бархатный голос, богатый тембр и, конечно, тёплый ламповый саунд! Почему звук такой разный? От чего зависит звучание и наше восприятие? Что мы вообще знаем об акустике, собственном голосе и как можем применить эти знания? От шёпота до УЗИ – Варя расскажет обо всём.</td>\n",
       "      <td>A woman is talking to a group of people and then a man is shown standing in front of a wall. A woman is standing in front of a computer screen and is talking to another woman in a foreign language. A man is standing in front of a stage and he is playing a song on a guitar.</td>\n",
       "      <td>Женщина стоит перед экраном компьютера и разговаривает с другой женщиной на иностранном языке. Мужчина стоит перед сценой и играет песню на гитаре.</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb40ed",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6e8bdba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import comet_ml\n",
    "\n",
    "from accelerate import notebook_launcher\n",
    "from accelerate.utils import set_seed\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5bd45455",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"COMET_LOG_ASSETS\"] = \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba9e61",
   "metadata": {},
   "source": [
    "### facebook bart-large-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bec6705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"IlyaGusev/mbart_ru_sum_gazeta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c6869",
   "metadata": {},
   "source": [
    "#### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5b0f0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e64e41c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ded58d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bcf6d8d04d4d0a802c746e615772b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/95 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "befffc34be97465e80db7be7bfa32df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/24 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "510664dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = tokenizer.model_max_length\n",
    "BLOCK_SIZE = 1024\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "05848f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=BLOCK_SIZE, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=BLOCK_SIZE, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4528c461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a09ab25c134d37bdd07d7879562626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/95 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5cfef0b5bb474bb91b8724f925797f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/24 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_proc=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "12d22a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cfa16a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b464bb",
   "metadata": {},
   "source": [
    "#### GPU runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "84001b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c49e7b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep 30 15:46:27 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    26W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:02:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    28W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e39834",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f5b00157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "427431e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5549dc",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "89e010a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_ml.init( project_name = \"KaiTube\", experiment_name = \"Summarization-rugazeta-gas-1024-video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0f2ee276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function():\n",
    "    \n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"IlyaGusev-mbart_ru_sum_gazeta-finetune-1024-gas-video\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=3,\n",
    "        num_train_epochs=20,\n",
    "        predict_with_generate=True,\n",
    "        fp16=True,\n",
    "        gradient_accumulation_steps=8,\n",
    "        save_steps=55\n",
    "    )\n",
    "    \n",
    "    set_seed(42)\n",
    "    torch.manual_seed(7)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), training_args.learning_rate)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=training_args.learning_rate,\n",
    "        steps_per_epoch=int(len(lm_datasets[\"train\"])),\n",
    "        epochs=training_args.per_device_train_batch_size,\n",
    "        anneal_strategy='linear'\n",
    "    )\n",
    "    \n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=lm_datasets[\"train\"],\n",
    "        eval_dataset=lm_datasets[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        optimizers=(optimizer, scheduler)\n",
    "    )\n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4280b3db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m You are trying to log string value as a metric. This is not recommended.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/gumaonelove/kaitube/871884d2aedb4b04867d9f5c4228b4ed\n",
      "\n",
      "You're using a MBartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a MBartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/60 06:34 < 00:29, 0.14 it/s, Epoch 18.33/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.651559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.517689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.416700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.457882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.916700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.257483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.124197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.458300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.013084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.936275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.916700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.865460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.291700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.799875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.751960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.702423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.654174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.612473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.578027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.166700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.546773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.529308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.041700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.510050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.492802</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>57.166700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/60 06:34 < 00:29, 0.14 it/s, Epoch 18.33/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.651559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.517689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.416700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.457882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.916700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.257483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.124197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.458300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.013084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.936275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.916700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.865460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.291700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.799875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.751960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.702423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.654174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.612473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.578027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.166700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.546773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.529308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.041700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.510050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.492802</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>57.166700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "An issue was found when launching the training: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/serialization.py\", line 441, in save\n    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/serialization.py\", line 668, in _save\n    zip_file.write_record(name, storage.data_ptr(), num_bytes)\nRuntimeError: [enforce fail at inline_container.cc:471] . PytorchStreamWriter failed writing file data/3: file write failed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/accelerate/utils/launch.py\", line 543, in __call__\n    self.launcher(*args)\n  File \"/tmp/ipykernel_9564/2908810603.py\", line 40, in training_function\n    trainer.train()\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/transformers/trainer.py\", line 1555, in train\n    return inner_training_loop(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/transformers/trainer.py\", line 1929, in _inner_training_loop\n    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/transformers/trainer.py\", line 2267, in _maybe_log_save_evaluate\n    self._save_checkpoint(model, trial, metrics=metrics)\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/transformers/trainer.py\", line 2373, in _save_checkpoint\n    torch.save(self.lr_scheduler.state_dict(), os.path.join(output_dir, SCHEDULER_NAME))\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/comet_ml/monkey_patching.py\", line 353, in wrapper\n    raise exception_raised\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/comet_ml/monkey_patching.py\", line 324, in wrapper\n    return_value = original(*args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/serialization.py\", line 440, in save\n    with _open_zipfile_writer(f) as opened_zipfile:\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/serialization.py\", line 291, in __exit__\n    self.file_like.write_end_of_file()\nRuntimeError: [enforce fail at inline_container.cc:337] . unexpected pos 7623646464 vs 7623646360\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/asr/lib/python3.11/site-packages/accelerate/launchers.py:154\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     start_processes(launcher, args\u001b[38;5;241m=\u001b[39margs, nprocs\u001b[38;5;241m=\u001b[39mnum_processes, start_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfork\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/asr/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:197\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mjoin():\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:160\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    159\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/serialization.py\", line 441, in save\n    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/serialization.py\", line 668, in _save\n    zip_file.write_record(name, storage.data_ptr(), num_bytes)\nRuntimeError: [enforce fail at inline_container.cc:471] . PytorchStreamWriter failed writing file data/3: file write failed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/accelerate/utils/launch.py\", line 543, in __call__\n    self.launcher(*args)\n  File \"/tmp/ipykernel_9564/2908810603.py\", line 40, in training_function\n    trainer.train()\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/transformers/trainer.py\", line 1555, in train\n    return inner_training_loop(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/transformers/trainer.py\", line 1929, in _inner_training_loop\n    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/transformers/trainer.py\", line 2267, in _maybe_log_save_evaluate\n    self._save_checkpoint(model, trial, metrics=metrics)\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/transformers/trainer.py\", line 2373, in _save_checkpoint\n    torch.save(self.lr_scheduler.state_dict(), os.path.join(output_dir, SCHEDULER_NAME))\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/comet_ml/monkey_patching.py\", line 353, in wrapper\n    raise exception_raised\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/comet_ml/monkey_patching.py\", line 324, in wrapper\n    return_value = original(*args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/serialization.py\", line 440, in save\n    with _open_zipfile_writer(f) as opened_zipfile:\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/serialization.py\", line 291, in __exit__\n    self.file_like.write_end_of_file()\nRuntimeError: [enforce fail at inline_container.cc:337] . unexpected pos 7623646464 vs 7623646360\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m notebook_launcher(training_function, num_processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, mixed_precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/asr/lib/python3.11/site-packages/accelerate/launchers.py:164\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    158\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA has been initialized before the `notebook_launcher` could create a forked subprocess. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis likely stems from an outside import causing issues once the `notebook_launcher()` is called. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease review your imports and test them when running the `notebook_launcher()` to identify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich one is problematic and causing CUDA to be initialized.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    163\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn issue was found when launching the training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# No need for a distributed launch otherwise as it's either CPU, GPU or MPS.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_mps_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: An issue was found when launching the training: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/serialization.py\", line 441, in save\n    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/serialization.py\", line 668, in _save\n    zip_file.write_record(name, storage.data_ptr(), num_bytes)\nRuntimeError: [enforce fail at inline_container.cc:471] . PytorchStreamWriter failed writing file data/3: file write failed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/accelerate/utils/launch.py\", line 543, in __call__\n    self.launcher(*args)\n  File \"/tmp/ipykernel_9564/2908810603.py\", line 40, in training_function\n    trainer.train()\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/transformers/trainer.py\", line 1555, in train\n    return inner_training_loop(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/transformers/trainer.py\", line 1929, in _inner_training_loop\n    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/transformers/trainer.py\", line 2267, in _maybe_log_save_evaluate\n    self._save_checkpoint(model, trial, metrics=metrics)\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/transformers/trainer.py\", line 2373, in _save_checkpoint\n    torch.save(self.lr_scheduler.state_dict(), os.path.join(output_dir, SCHEDULER_NAME))\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/comet_ml/monkey_patching.py\", line 353, in wrapper\n    raise exception_raised\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/comet_ml/monkey_patching.py\", line 324, in wrapper\n    return_value = original(*args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/serialization.py\", line 440, in save\n    with _open_zipfile_writer(f) as opened_zipfile:\n  File \"/home/asr/miniconda3/envs/asr/lib/python3.11/site-packages/torch/serialization.py\", line 291, in __exit__\n    self.file_like.write_end_of_file()\nRuntimeError: [enforce fail at inline_container.cc:337] . unexpected pos 7623646464 vs 7623646360\n"
     ]
    }
   ],
   "source": [
    "trainer = notebook_launcher(training_function, num_processes=2, mixed_precision='fp16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc053f55",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b93f5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db6f1ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"IlyaGusev-mbart_ru_sum_gazeta-finetune-1024/checkpoint-500/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f838e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"[0.18s -> 2.70s]  Ты видел в жизни когда-нибудь Киркорова?\n",
    "[2.70s -> 7.61s]  Да. Я работал на ЛАФ-радио, брат.\n",
    "[7.61s -> 11.25s]  Вот это руками надо вытаскивать. Может, слайсами, Крис?\n",
    "[11.25s -> 15.37s]  Я могу про себя много чего наговорить, но будет ли это правдой?\n",
    "[15.37s -> 18.21s]  Ну, господи, как будто я другого спрашивал.\n",
    "[18.21s -> 20.85s]  Я худший готовитель истории этого шоу.\n",
    "[20.85s -> 23.09s]  Банданы, я считаю, что это говно.\n",
    "[23.09s -> 24.69s]  До февраля? Сука!\n",
    "[24.69s -> 27.69s]  Я думаю, с этого должен выпуск начинаться,\n",
    "[27.69s -> 30.01s]  типа нарезок, как падает что-то.\n",
    "[30.01s -> 31.01s]  Почему?\n",
    "[34.57s -> 37.45s]  Привет всем пережившим и отдохнувшим...\n",
    "[37.45s -> 38.45s]  Блин.\n",
    "[38.45s -> 40.17s]  В гостях у нас сегодня...\n",
    "[40.17s -> 41.65s]  Да, дурак? Да.\n",
    "[41.65s -> 47.06s]  Привет всем пережившим и отдохнувшим.\n",
    "[47.06s -> 48.78s]  Меня зовут Ярослав Грина,\n",
    "[48.78s -> 51.82s]  это первый выпуск шоу Kitchen Stories в 2022 году.\n",
    "[51.82s -> 53.82s]  Ну а в гостях у меня человек,\n",
    "[53.82s -> 56.98s]  имя которого вы знаете, это Basic Boy, Макс Салют.\n",
    "[56.98s -> 57.98s]  Салют.\n",
    "[57.98s -> 60.06s]  Прежде чем мы начнем готовить,\n",
    "[60.06s -> 62.86s]  я вкратце расскажу правила нашей программы.\n",
    "[62.86s -> 65.10s]  Я жду от тебя классное настроение,\n",
    "[65.14s -> 68.02s]  интересный рецепт и увлекательные истории.\n",
    "[68.02s -> 69.02s]  Все будет.\n",
    "[69.02s -> 70.70s]  Что мы сегодня готовим?\n",
    "[70.70s -> 74.46s]  Сегодня мы готовим сельдь под шубой по рецепту моей мамы.\n",
    "[74.46s -> 77.62s]  И картошечку со сливочным соусом, с грибочками.\n",
    "[77.62s -> 80.22s]  По рецепту другой моей любимой женщины,\n",
    "[80.22s -> 81.22s]  моя невеста Крис.\n",
    "[81.22s -> 83.94s]  Сегодня будет два блюда, давайте кайфанем.\n",
    "[83.94s -> 86.58s]  Мне кажется, у ребят уже сегодня потекли.\n",
    "[86.58s -> 89.18s]  Расскажи, что нам для этого потребуется.\n",
    "[89.18s -> 92.50s]  Селедочка, картошечка, свекла, грибочки, зеленечки,\n",
    "[92.58s -> 94.06s]  луечек и майонезик.\n",
    "[94.06s -> 97.50s]  И еще вот там чеснок, перец, соль, сливки и лучок.\n",
    "[97.50s -> 98.50s]  Еще один.\n",
    "[98.50s -> 99.50s]  С чего мы начнем?\n",
    "[99.50s -> 103.22s]  Мы поставили остужаться картошечку, свеколку у нас варится.\n",
    "[103.22s -> 105.62s]  Мы сейчас будем разделывать селедку.\n",
    "[105.62s -> 109.58s]  Я не то чтобы мастер в этом деле, так что будем фристалить.\n",
    "[109.58s -> 112.98s]  Я позвонил маме, автору этого рецепта, так скажем.\n",
    "[112.98s -> 115.30s]  Она мне расписала, как это делать,\n",
    "[115.30s -> 118.50s]  но я не очень уверен в своих силах в этом плане.\n",
    "[118.50s -> 120.02s]  Надеюсь, все получится.\n",
    "[120.02s -> 121.70s]  Для этого есть мои силы.\n",
    "[122.38s -> 124.14s]  Ну что, народ, погнали.\n",
    "[124.14s -> 127.74s]  А почему ты решил готовить именно селедку под шубой?\n",
    "[127.74s -> 131.10s]  Во-первых, это такой новогодний рецепт, прикольный.\n",
    "[131.10s -> 132.86s]  Мама постоянно его делала.\n",
    "[132.86s -> 136.06s]  Это первое, что пришло в голову из таких рецептов,\n",
    "[136.06s -> 137.62s]  которые я люблю реально.\n",
    "[137.62s -> 141.18s]  Мама очень круто готовит, мне всегда очень нравилось.\n",
    "[141.18s -> 144.78s]  И охота увековечить ее рецепты в пространстве интернета\n",
    "[144.78s -> 146.06s]  и поделиться этим.\n",
    "[146.06s -> 148.18s]  Я очень люблю все эти продукты.\n",
    "[148.18s -> 150.30s]  Как часто ты сам готовишь?\n",
    "[150.46s -> 153.90s]  Слушай, я не суперчасто готовлю, я люблю готовить.\n",
    "[153.90s -> 157.30s]  Мне это нравится, но я все никак не могу заставить.\n",
    "[157.30s -> 160.54s]  Ничего себе приготовить, кроме завтрака с утра.\n",
    "[160.54s -> 163.14s]  Но у меня неплохо получается всячески.\n",
    "[163.14s -> 166.46s]  Последнее, наверное, что я готовил, это панкейки.\n",
    "[166.46s -> 168.90s]  Мне очень понравилось, если честно.\n",
    "[168.90s -> 172.62s]  А так я все никак не могу заставить, просто это делать.\n",
    "[172.62s -> 177.18s]  Мне реально нравится этот процесс, очень умиротворяет медитативно.\n",
    "[177.22s -> 179.42s]  Здесь проходимся, тоже глубоко.\n",
    "[179.42s -> 181.02s]  Насколько я понял, да.\n",
    "[181.02s -> 183.26s]  Чтобы у нас две части получилось,\n",
    "[183.26s -> 186.18s]  и там где-то посредине останется позвоночник.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a07f51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "reg = re.compile('[^а-яА-Я ]')\n",
    "text = reg.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ba4a44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Добро пожаловать на шоу «Макс Салют»! Шоу, в котором обсуждаются актуальные новости страны и мира, в котором обсуждаются актуальные новости страны и мира. В этом выпуске мы пригласим в нашу студию одного из самых ярких и харизматичных музыкантов России, а также приготовим традиционное блюдо из сельдьё под шубой по рецепту мамы. Приятного аппетита!'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4496ec",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05a535fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"IlyaGusev/mbart_ru_sum_gazeta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "753babc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Стеклянная ваза с нарисованными на ней цветами Стеклянная ваза с нарисованным на ней лицом Стеклянная скульптура с надписью Я не могу видеть изображение выше Чернобелое фото человека сидящего на полу Стеклянная скульптура слона сидящего на столе Стеклянная скульптура слона сидящего на столе Стеклянная ваза с нарисованным на ней лицом Стеклянная ваза стоит на столе Синебелый уличный фонарь и дерево Крупный план часов на стене здания Крупный план цветка на фоне неба Чернобелая фотография человека стоящего на коленях на земле Крупный план уличного знака на фоне голубого неба Крупный план знака остановки на фоне неба Уличная сцена с изображением знака Стоп Чернобелое фото трех человек держащих плюшевых мишек Группа людей стоящих рядом друг с'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9e983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "asr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
